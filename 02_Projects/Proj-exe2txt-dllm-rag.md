## 0. 개요
- 목표:
  - exe → 텍스트(디스어셈/IR) 변환 도구(exe2txt)와 Noel의 analyser를 결합하여,
    - 함수 단위로 구조화된 바이너리 분석 결과를 생성하고
    - Qwen2.5-Coder-Instruct 기반 도메인 특화 dLLM을 파인튜닝하며
    - 함수 단위 RAG 시스템으로 연동되는 “LLM 기반 바이너리 분석/디컴파일 플랫폼” POC 구축
- 범위:
  - 1단계: 공개 데이터셋 + Qwen2.5-Coder-Instruct 파인튜닝(이미 별도 진행)
  - 이 문서: 2단계 확장 (exe2txt + synthetic 데이터 파이프라인 + 함수 단위 RAG 설계)
- 마감: 미정 (1단계 베이스 모델 안정화 이후 착수 기준으로 별도 설정)

## 1. 로드맵
- [ ] 요구사항·유즈케이스 정리
  - [ ] 지원 태스크 정의: 함수 요약, 시그니처 추론, C 유사 코드 복원, 보안/취약점 분석 등
  - [ ] 타깃 유저/시나리오 정리 (리버스 엔지니어, 보안 분석, 내부 도구용 등)
- [ ] exe2txt 파이프라인 설계·MVP 구현
  - [ ] C 코드 템플릿/생성기 설계 (포인터, 구조체, 비트 연산, 콜백 등 다양한 패턴 포함)
  - [ ] clang/gcc 기반 컴파일 파이프라인 구축 (`-O0..3`, 32/64bit 등 옵션 다양화)
  - [ ] 디스어셈/IR 추출 및 텍스트 포맷 정규화 (주소/노이즈 최소화, 명령어·피연산자·제어흐름 중심)
- [ ] analyser 확장 및 함수 단위 JSON 스키마 정의
  - [ ] 함수 경계/메타데이터 추출 (주소, 섹션, 크기, calling convention 추정)
  - [ ] call graph / xref / 문자열·전역 변수 참조 정보 수집
  - [ ] 함수 단위 RAG용 JSON/NDJSON 스키마 설계 및 export CLI 구현
- [ ] synthetic + real 데이터셋 구성
  - [ ] synthetic C → exe → 함수 단위 JSON 생성 파이프라인 완성
  - [ ] JSON에 `source_code`, `source_comment`, `task_labels` 등 LLM 학습용 필드 추가
  - [ ] 라이선스 괜찮은 소규모 C 오픈소스 프로젝트 일부를 혼합하여 분포 현실화
- [ ] 파인튜닝 데이터셋/포맷 설계
  - [ ] instruction-style 포맷 정의 (요약/시그니처 추론/C 복원/보안 분석 등 태스크별 템플릿)
  - [ ] 1단계 공개 데이터셋 포맷과 호환되도록 스키마 정렬
  - [ ] 샘플 데이터 생성 및 품질 점검
- [ ] Qwen2.5 기반 dLLM 2단계 파인튜닝
  - [ ] 베이스 모델(Qwen2.5-Coder-Instruct) 설정·학습 환경 구성
  - [ ] synthetic + real 바이너리 데이터셋으로 도메인 특화 instruction tuning 수행
  - [ ] baseline(원본 Qwen) 대비 성능 비교 실험 설계
- [ ] 평가(Eval) 설계·실행
  - [ ] 태스크별 지표 정의 (요약 정확도, 시그니처 추론 정확도, C 복원 토큰/구문 매칭률 등)
  - [ ] 자동 평가 + 일부 수동 리뷰 세트 구성
  - [ ] 결과 리포트/그래프 정리
- [ ] 함수 단위 RAG 인덱스 및 쿼리 경로 설계
  - [ ] 벡터 임베딩 인덱스 설계 (디스어셈/IR/문자열 기반)
  - [ ] call graph를 활용한 k-hop 이웃 retrieval 전략 설계
  - [ ] 질의 유형별 retrieval 플로우 정의 (주소 기반, 의미 기반, 취약점 탐색 등)
- [ ] 데모/사용자 인터페이스 구현
  - [ ] CLI 또는 간단한 웹/에디터 플러그인 UI로 “함수 선택 → 요약/복원/분석” 플로우 구현
  - [ ] 내부/포트폴리오용 데모 시나리오 스크립트 작성
- [ ] 문서화·포트폴리오화
  - [ ] 전체 아키텍처/데이터 파이프라인/RAG 구조 문서화
  - [ ] GitHub README 및 포트폴리오 설명용 요약/슬라이드 작성
  - [ ] LLM 엔지니어 포지션을 타깃으로 한 “프로젝트 포지셔닝 문구” 정리

## 2. 회의/AI 대화 로그

### 2025-12-05
- ChatGPT 요약:
  - 1단계로 공개 데이터셋 + Qwen2.5-Coder-Instruct 기반 텍스트 위주의 리버스/보안 LLM 파인튜닝을 진행하고, 본 프로젝트는 그 위에 얹는 2단계 확장( exe2txt + 함수 단위 RAG + 도메인 특화 dLLM)으로 정의.
  - C 코드 자동 생성 → 컴파일 → 디스어셈/IR 텍스트(exe2txt) → Noel의 analyser로 함수 단위 JSON/메타데이터 추출 → instruction 데이터셋 구성 → Qwen2.5 dLLM 파인튜닝 → 함수 단위 RAG 인덱스 구축이라는 전체 파이프라인 구조를 설계.
  - 이 프로젝트는 LLM 파인튜닝, 데이터 파이프라인, RAG 설계, 도구/에이전트 연동을 모두 포함하여 LLM 엔지니어 채용에서 요구하는 스킬셋과 잘 맞고, 바이너리/리버스라는 니치 도메인 덕분에 차별성이 높음.
  - 보완 포인트로는 평가 지표(Eval) 명시, 간단한 데모 UI/플러그인 구현, 일반 비즈니스 도메인용 LLM/RAG 프로젝트 1~2개를 추가하여 “니치 + 범용” 경험을 동시에 보여주는 방향을 제안.
